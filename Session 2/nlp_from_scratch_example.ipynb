{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a6ce2d5",
   "metadata": {},
   "source": [
    "# 1. Import data & define global variables"
   ]
  },
  {
   "cell_type": "code",
   "id": "2d92136d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.097408Z",
     "start_time": "2026-01-19T07:47:18.094186Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "CSV_FILE = \"foodly_feedback.csv\""
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "id": "6f9b513d",
   "metadata": {},
   "source": [
    "# 2. Create helper classes & functions"
   ]
  },
  {
   "cell_type": "code",
   "id": "dc36fdbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.104771Z",
     "start_time": "2026-01-19T07:47:18.097408Z"
    }
   },
   "source": [
    "def parse_line(s):\n",
    "    \"\"\"\n",
    "    Parse a single line from the CSV file with proper handling of quoted fields.\n",
    "\n",
    "    This function handles CSV lines that contain commas within quoted fields,\n",
    "    properly extracting the id, channel, rating, and text while preserving\n",
    "    internal punctuation and formatting.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    s : str\n",
    "        A single line from the CSV file\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (doc_id (int), channel (str), rating (int), text (str))\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> parse_line('1,app_store,5,\"Love this app!\"')\n",
    "    (1, 'app_store', 5, 'Love this app!')\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    - Handles double quotes within text by replacing \"\" with \"\n",
    "    - Splits on first 3 commas only to preserve commas in text field\n",
    "    \"\"\"\n",
    "    s = s.strip().strip('\"')\n",
    "    doc_id, channel, rating, text = s.split(\",\", 3)\n",
    "    text = text.strip().strip('\"').replace('\"\"','\"')\n",
    "    return int(doc_id), channel, int(rating), text\n",
    "\n",
    "def clean_text(t):\n",
    "    \"\"\"\n",
    "    Clean and normalize text for NLP processing.\n",
    "\n",
    "    This function performs several text cleaning operations:\n",
    "    1. Converts to lowercase\n",
    "    2. Removes URLs (http/https/www)\n",
    "    3. Removes all characters except letters, apostrophes, and spaces\n",
    "    4. Collapses multiple spaces into single spaces\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    t : str\n",
    "        Raw text string to clean\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    str\n",
    "        Cleaned and normalized text\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> clean_text(\"I LOVE this app! Check www.example.com\")\n",
    "    'i love this app check'\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    Apostrophes are preserved to keep contractions like \"didn't\", \"it's\"\n",
    "    \"\"\"\n",
    "    t = str(t).lower()\n",
    "    # Remove URLs\n",
    "    t = re.sub(r\"http\\S+|www\\.\\S+\", \" \", t)\n",
    "    # Keep only letters, apostrophes, and spaces\n",
    "    t = re.sub(r\"[^a-z'\\s]\", \" \", t)\n",
    "    # Collapse multiple spaces\n",
    "    return re.sub(r\"\\s+\", \" \", t).strip()\n",
    "\n",
    "def tokenize(t):\n",
    "    \"\"\"\n",
    "    Tokenize text into individual words.\n",
    "\n",
    "    This function first cleans the text using clean_text(), then splits it\n",
    "    into individual words (tokens) and filters out any empty strings.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    t : str\n",
    "        Text string to tokenize\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    list of str\n",
    "        List of individual word tokens\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    >>> tokenize(\"Love this app! It's great.\")\n",
    "    ['love', 'this', 'app', \"it's\", 'great']\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    All tokens are at least 1 character long\n",
    "    \"\"\"\n",
    "    return [w for w in clean_text(t).split() if len(w) >= 1]"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "3878f77f",
   "metadata": {},
   "source": [
    "# 3. Import data"
   ]
  },
  {
   "cell_type": "code",
   "id": "f9732afd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.115176Z",
     "start_time": "2026-01-19T07:47:18.108942Z"
    }
   },
   "source": [
    "# Filename: \"foodly_feedback.csv\"\n",
    "lines = [l for l in open(CSV_FILE) if l.strip()]\n",
    "rows = [parse_line(l) for l in lines[1:]]\n",
    "df = pd.DataFrame(rows, columns=[\"doc_id\",\"channel\",\"rating\",\"raw_text\"])\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id    channel  rating  \\\n",
      "0       1  app_store       5   \n",
      "1       2     in_app       1   \n",
      "2       3     in_app       2   \n",
      "3       4      email       3   \n",
      "4       5      email       1   \n",
      "\n",
      "                                            raw_text  \n",
      "0  Love this app! use it every day for ordering p...  \n",
      "1  I HATE the new update...crashes   every time I...  \n",
      "2  delivery was late late late. driver said 'syst...  \n",
      "3  Great UI, but why do you need my phone # again???  \n",
      "4  Support didn't reply to my email (john.doe@exa...  \n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "id": "68b3fbf0",
   "metadata": {},
   "source": [
    "# 4. Curate dataset"
   ]
  },
  {
   "cell_type": "code",
   "id": "174f2986",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.123627Z",
     "start_time": "2026-01-19T07:47:18.119702Z"
    }
   },
   "source": [
    "df = df[[\"doc_id\",\"rating\",\"raw_text\"]].dropna()\n",
    "print(df.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id  rating                                           raw_text\n",
      "0       1       5  Love this app! use it every day for ordering p...\n",
      "1       2       1  I HATE the new update...crashes   every time I...\n",
      "2       3       2  delivery was late late late. driver said 'syst...\n",
      "3       4       3  Great UI, but why do you need my phone # again???\n",
      "4       5       1  Support didn't reply to my email (john.doe@exa...\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "id": "a0e6f082",
   "metadata": {},
   "source": [
    "# 5. Extract docs"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e19a3f8",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.132646Z",
     "start_time": "2026-01-19T07:47:18.127539Z"
    }
   },
   "source": [
    "docs = df[\"raw_text\"].tolist()\n",
    "print(len(docs), docs[0][:80])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 Love this app! use it every day for ordering pizza.  super   fast delivery!!!\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "773f8dde",
   "metadata": {},
   "source": [
    "# 6. Clean text"
   ]
  },
  {
   "cell_type": "code",
   "id": "576eac13",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.143010Z",
     "start_time": "2026-01-19T07:47:18.138908Z"
    }
   },
   "source": [
    "df[\"clean_text\"] = df[\"raw_text\"].map(clean_text)\n",
    "print(df[[\"raw_text\",\"clean_text\"]].head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            raw_text  \\\n",
      "0  Love this app! use it every day for ordering p...   \n",
      "1  I HATE the new update...crashes   every time I...   \n",
      "2  delivery was late late late. driver said 'syst...   \n",
      "3  Great UI, but why do you need my phone # again???   \n",
      "4  Support didn't reply to my email (john.doe@exa...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  love this app use it every day for ordering pi...  \n",
      "1  i hate the new update crashes every time i try...  \n",
      "2  delivery was late late late driver said 'syste...  \n",
      "3        great ui but why do you need my phone again  \n",
      "4  support didn't reply to my email john doe exam...  \n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "markdown",
   "id": "d0274be0",
   "metadata": {},
   "source": [
    "# 7. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "id": "7b16c6d9",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.153585Z",
     "start_time": "2026-01-19T07:47:18.150148Z"
    }
   },
   "source": [
    "df[\"tokens\"] = df[\"clean_text\"].map(lambda x: x.split())\n",
    "print(df[\"tokens\"].head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [love, this, app, use, it, every, day, for, or...\n",
      "1    [i, hate, the, new, update, crashes, every, ti...\n",
      "2    [delivery, was, late, late, late, driver, said...\n",
      "3    [great, ui, but, why, do, you, need, my, phone...\n",
      "4    [support, didn't, reply, to, my, email, john, ...\n",
      "Name: tokens, dtype: object\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "94fa9692",
   "metadata": {},
   "source": [
    "# 8. Calculate term frequency"
   ]
  },
  {
   "cell_type": "code",
   "id": "ebdf08ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.162583Z",
     "start_time": "2026-01-19T07:47:18.157432Z"
    }
   },
   "source": [
    "tf = df[\"tokens\"].map(Counter).tolist()\n",
    "print(tf[0].most_common(10))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('love', 1), ('this', 1), ('app', 1), ('use', 1), ('it', 1), ('every', 1), ('day', 1), ('for', 1), ('ordering', 1), ('pizza', 1)]\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "7bccb69e",
   "metadata": {},
   "source": [
    "# 9. Calculate document frequency"
   ]
  },
  {
   "cell_type": "code",
   "id": "27e96142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.172336Z",
     "start_time": "2026-01-19T07:47:18.167556Z"
    }
   },
   "source": [
    "dfreq = Counter()\n",
    "for toks in df[\"tokens\"]:\n",
    "    dfreq.update(set(toks))\n",
    "print(len(dfreq))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "07f938bd",
   "metadata": {},
   "source": [
    "# 10. Calculate inverse document frequency"
   ]
  },
  {
   "cell_type": "code",
   "id": "2b4c1d22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.181264Z",
     "start_time": "2026-01-19T07:47:18.177859Z"
    }
   },
   "source": [
    "N = len(df)\n",
    "idf = {w: math.log((N+1)/(dfreq[w]+1)) + 1 for w in dfreq}\n",
    "print(list(idf.items())[:5])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('delivery', 3.0476928433652555), ('app', 2.35454566280531), ('love', 3.0476928433652555), ('use', 3.740840023925201), ('pizza', 3.740840023925201)]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "1e35fe27",
   "metadata": {},
   "source": [
    "# 11. Create dataframe: doc_id|rating|token|score"
   ]
  },
  {
   "cell_type": "code",
   "id": "fbb701ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.194898Z",
     "start_time": "2026-01-19T07:47:18.188078Z"
    }
   },
   "source": [
    "recs = []\n",
    "for (doc_id, rating, toks), cnts in zip(df[[\"doc_id\",\"rating\",\"tokens\"]].values, tf):\n",
    "    L = max(len(toks), 1)\n",
    "    for w, c in cnts.items():\n",
    "        recs.append((doc_id, rating, w, (c/L) * idf[w]))\n",
    "\n",
    "scores = pd.DataFrame(recs, columns=[\"doc_id\",\"rating\",\"token\",\"score\"])\n",
    "print(scores.head())"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   doc_id  rating token     score\n",
      "0       1       5  love  0.234438\n",
      "1       1       5  this  0.256567\n",
      "2       1       5   app  0.181119\n",
      "3       1       5   use  0.287757\n",
      "4       1       5    it  0.287757\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "c47b8859",
   "metadata": {},
   "source": [
    "# 12. Get highest score tokens for high rating and low rating comments"
   ]
  },
  {
   "cell_type": "code",
   "id": "c786f12b",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.205229Z",
     "start_time": "2026-01-19T07:47:18.200010Z"
    }
   },
   "source": [
    "top = lambda d: d.groupby(\"token\")[\"score\"].mean().sort_values(ascending=False).head(20)\n",
    "\n",
    "high_top = top(scores[scores.rating >= 4])\n",
    "low_top  = top(scores[scores.rating <= 2])\n",
    "\n",
    "print(\"\\nTop tokens for HIGH ratings (4-5 stars):\")\n",
    "print(high_top)\n",
    "print(\"\\nTop tokens for LOW ratings (1-2 stars):\")\n",
    "print(low_top)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top tokens for HIGH ratings (4-5 stars):\n",
      "token\n",
      "pay           0.667075\n",
      "was           0.555896\n",
      "hurt          0.415649\n",
      "dark          0.415649\n",
      "mode          0.415649\n",
      "feature       0.415649\n",
      "eyes          0.415649\n",
      "request       0.415649\n",
      "at            0.415649\n",
      "night         0.415649\n",
      "add           0.374084\n",
      "convenient    0.374084\n",
      "apple         0.374084\n",
      "seem          0.374084\n",
      "than          0.374084\n",
      "remember      0.374084\n",
      "paypal        0.374084\n",
      "website       0.374084\n",
      "very          0.374084\n",
      "higher        0.374084\n",
      "Name: score, dtype: float64\n",
      "\n",
      "Top tokens for LOW ratings (1-2 stars):\n",
      "token\n",
      "late           1.020229\n",
      "fee            0.831298\n",
      "number         0.534406\n",
      "arrived        0.534406\n",
      "never          0.534406\n",
      "refund         0.534406\n",
      "sus            0.467605\n",
      "fake           0.467605\n",
      "all            0.467605\n",
      "still          0.467605\n",
      "stars          0.467605\n",
      "restaurant     0.467605\n",
      "reinstalled    0.467605\n",
      "ratings        0.467605\n",
      "feel           0.467605\n",
      "loading        0.467605\n",
      "stuck          0.467605\n",
      "uninstalled    0.467605\n",
      "tip            0.415649\n",
      "small          0.415649\n",
      "Name: score, dtype: float64\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "f0486524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-19T07:47:18.210946Z",
     "start_time": "2026-01-19T07:47:18.207240Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
